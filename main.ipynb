{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sohan/anaconda3/envs/kaggle-amex/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import scipy.stats\n",
    "import warnings\n",
    "import gc\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from lightgbm import LGBMClassifier, log_evaluation\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "\n",
    "INFERENCE = True # set to False if you only want to cross-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1\n",
      "Computed avg 1\n",
      "Computed last 1\n",
      "Read 0\n",
      "Computed avg 0\n",
      "Computed last 0\n",
      "Shapes: (458913, 197) (458913,) (924621, 197)\n",
      "CPU times: user 31.4 s, sys: 11.2 s, total: 42.6 s\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_avg = ['B_1', 'B_11', 'B_16', 'B_17', 'B_18', 'B_2', 'B_20',\n",
    "                'B_28', 'B_3', 'B_4', 'B_5', 'B_7', 'B_9', 'D_112',\n",
    "                'D_121', 'D_141', 'D_39', 'D_41', 'D_42', 'D_43',\n",
    "                'D_44', 'D_45', 'D_46', 'D_47', 'D_48', 'D_49', \n",
    "                'D_50', 'D_51', 'D_53', 'D_54', 'D_56', 'D_58', \n",
    "                'D_59', 'D_60', 'D_91', 'P_2', 'P_3', 'R_1', 'R_2', \n",
    "                'R_27', 'R_3', 'R_7', 'S_11', 'S_26', 'S_3', 'S_5']\n",
    "features_last = ['B_1', 'B_10', 'B_11', 'B_12', 'B_13', 'B_15', 'B_16',\n",
    "                 'B_17', 'B_18', 'B_19', 'B_2', 'B_20', 'B_22', 'B_23',\n",
    "                 'B_24', 'B_25', 'B_26', 'B_27', 'B_28', 'B_29', 'B_3',\n",
    "                 'B_32', 'B_33', 'B_36', 'B_38', 'B_39', 'B_4', 'B_40',\n",
    "                 'B_41', 'B_42', 'B_5', 'B_6', 'B_7', 'B_8', 'B_9',\n",
    "                 'D_102', 'D_103', 'D_105', 'D_106', 'D_107', 'D_109',\n",
    "                 'D_112', 'D_115', 'D_117', 'D_118', 'D_119', 'D_120',\n",
    "                 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_127', \n",
    "                 'D_129', 'D_132', 'D_133', 'D_135', 'D_136', 'D_137', \n",
    "                 'D_140', 'D_141', 'D_143', 'D_145', 'D_39', 'D_41',\n",
    "                 'D_42', 'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48',\n",
    "                 'D_49', 'D_50', 'D_51', 'D_52', 'D_53', 'D_54', 'D_55',\n",
    "                 'D_56', 'D_58', 'D_59', 'D_60', 'D_61', 'D_62', 'D_63',\n",
    "                 'D_64', 'D_66', 'D_70', 'D_72', 'D_73', 'D_74', 'D_75',\n",
    "                 'D_76', 'D_77', 'D_78', 'D_79', 'D_80', 'D_82', 'D_83',\n",
    "                 'D_84', 'D_86', 'D_91', 'D_92', 'D_93', 'D_94', 'D_96',\n",
    "                 'P_2', 'P_3', 'R_1', 'R_10', 'R_11', 'R_12', 'R_13',\n",
    "                 'R_14', 'R_15', 'R_17', 'R_18', 'R_19', 'R_2', 'R_20', \n",
    "                 'R_21', 'R_22', 'R_24', 'R_25', 'R_26', 'R_27', 'R_3',\n",
    "                 'R_4', 'R_5', 'R_7', 'R_8', 'R_9', 'S_11', 'S_12',\n",
    "                 'S_13', 'S_15', 'S_17', 'S_20', 'S_22', 'S_23', \n",
    "                 'S_24', 'S_25', 'S_26', 'S_27', 'S_3', 'S_5', 'S_6',\n",
    "                 'S_7', 'S_8', 'S_9']\n",
    "                 \n",
    "\n",
    "train_test = [None, None] # first element is train, second element is test\n",
    "for i in [1, 0] if INFERENCE else [0]:\n",
    "    train_test[i] = pd.read_feather(['dataset/train_data.ftr',\n",
    "                                     'dataset/test_data.ftr'][i])\n",
    "    cid = pd.Categorical(train_test[i].pop('customer_ID'), ordered=True)\n",
    "    last = (cid != np.roll(cid, -1)) # mask for last statement of every customer\n",
    "    if i == 0: # train\n",
    "        target = train_test[0].loc[last, 'target']\n",
    "    gc.collect()\n",
    "    print('Read', i)\n",
    "    df_avg = (train_test[i][features_avg]\n",
    "              .groupby(cid)\n",
    "              .mean()\n",
    "              .rename(columns={f: f\"{f}_avg\" for f in features_avg})\n",
    "             )\n",
    "    gc.collect()\n",
    "    print('Computed avg', i)\n",
    "    train_test[i] = (train_test[i].loc[last, features_last]\n",
    "                     .rename(columns={f: f\"{f}_last\" for f in features_last})\n",
    "                     .set_index(np.asarray(cid[last]))\n",
    "                    )\n",
    "    gc.collect()\n",
    "    print('Computed last', i)\n",
    "    train_test[i] = pd.concat([train_test[i], df_avg], axis=1)\n",
    "    del df_avg, cid, last\n",
    "\n",
    "train, test = tuple(train_test)\n",
    "del train_test\n",
    "if INFERENCE: print('Shapes:', train.shape, target.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true, y_pred, return_components=False) -> float:\n",
    "    \"\"\"Amex metric for ndarrays\"\"\"\n",
    "    def top_four_percent_captured(df) -> float:\n",
    "        \"\"\"Corresponds to the recall for a threshold of 4 %\"\"\"\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(df) -> float:\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(df) -> float:\n",
    "        \"\"\"Corresponds to 2 * AUC - 1\"\"\"\n",
    "        df2 = pd.DataFrame({'target': df.target, 'prediction': df.target})\n",
    "        df2.sort_values('prediction', ascending=False, inplace=True)\n",
    "        return weighted_gini(df) / weighted_gini(df2)\n",
    "\n",
    "    df = pd.DataFrame({'target': y_true.ravel(), 'prediction': y_pred.ravel()})\n",
    "    df.sort_values('prediction', ascending=False, inplace=True)\n",
    "    g = normalized_weighted_gini(df)\n",
    "    d = top_four_percent_captured(df)\n",
    "\n",
    "    if return_components: return g, d, 0.5 * (g + d)\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def lgb_amex_metric(y_true, y_pred):\n",
    "    \"\"\"The competition metric with lightgbm's calling convention\"\"\"\n",
    "    return ('amex',\n",
    "            amex_metric(y_true, y_pred),\n",
    "            True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 features**\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[100]\ttraining's binary_logloss: 0.252131\ttraining's amex: 0.768481\tvalid_1's binary_logloss: 0.256963\tvalid_1's amex: 0.761043\n",
      "[200]\ttraining's binary_logloss: 0.223666\ttraining's amex: 0.786201\tvalid_1's binary_logloss: 0.232191\tvalid_1's amex: 0.775342\n",
      "[300]\ttraining's binary_logloss: 0.2137\ttraining's amex: 0.798824\tvalid_1's binary_logloss: 0.225941\tvalid_1's amex: 0.782492\n",
      "[400]\ttraining's binary_logloss: 0.207649\ttraining's amex: 0.807022\tvalid_1's binary_logloss: 0.223329\tvalid_1's amex: 0.786702\n",
      "[500]\ttraining's binary_logloss: 0.202914\ttraining's amex: 0.813967\tvalid_1's binary_logloss: 0.221952\tvalid_1's amex: 0.788029\n",
      "[600]\ttraining's binary_logloss: 0.198764\ttraining's amex: 0.820531\tvalid_1's binary_logloss: 0.221152\tvalid_1's amex: 0.78903\n",
      "[700]\ttraining's binary_logloss: 0.195027\ttraining's amex: 0.826572\tvalid_1's binary_logloss: 0.220631\tvalid_1's amex: 0.789325\n",
      "[800]\ttraining's binary_logloss: 0.191415\ttraining's amex: 0.832154\tvalid_1's binary_logloss: 0.22032\tvalid_1's amex: 0.789414\n",
      "[900]\ttraining's binary_logloss: 0.188053\ttraining's amex: 0.837543\tvalid_1's binary_logloss: 0.220094\tvalid_1's amex: 0.790531\n",
      "[1000]\ttraining's binary_logloss: 0.184859\ttraining's amex: 0.842777\tvalid_1's binary_logloss: 0.219924\tvalid_1's amex: 0.790743\n",
      "[1100]\ttraining's binary_logloss: 0.181838\ttraining's amex: 0.847688\tvalid_1's binary_logloss: 0.219876\tvalid_1's amex: 0.791371\n",
      "[1200]\ttraining's binary_logloss: 0.178909\ttraining's amex: 0.852739\tvalid_1's binary_logloss: 0.219779\tvalid_1's amex: 0.792125\n",
      "[1300]\ttraining's binary_logloss: 0.176039\ttraining's amex: 0.857501\tvalid_1's binary_logloss: 0.219771\tvalid_1's amex: 0.79192\n",
      "\u001b[32m\u001b[1mFold 0 | 13:00 |  1332 trees |                Score = 0.79196\u001b[0m\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[100]\ttraining's binary_logloss: 0.252492\ttraining's amex: 0.769779\tvalid_1's binary_logloss: 0.256281\tvalid_1's amex: 0.75792\n",
      "[200]\ttraining's binary_logloss: 0.223949\ttraining's amex: 0.787033\tvalid_1's binary_logloss: 0.231157\tvalid_1's amex: 0.77104\n",
      "[300]\ttraining's binary_logloss: 0.213936\ttraining's amex: 0.799158\tvalid_1's binary_logloss: 0.224996\tvalid_1's amex: 0.779062\n",
      "[400]\ttraining's binary_logloss: 0.207733\ttraining's amex: 0.807333\tvalid_1's binary_logloss: 0.222483\tvalid_1's amex: 0.782805\n",
      "[500]\ttraining's binary_logloss: 0.202883\ttraining's amex: 0.814426\tvalid_1's binary_logloss: 0.22123\tvalid_1's amex: 0.785394\n",
      "[600]\ttraining's binary_logloss: 0.198792\ttraining's amex: 0.820953\tvalid_1's binary_logloss: 0.220549\tvalid_1's amex: 0.786395\n",
      "[700]\ttraining's binary_logloss: 0.195008\ttraining's amex: 0.826313\tvalid_1's binary_logloss: 0.220081\tvalid_1's amex: 0.787405\n",
      "[800]\ttraining's binary_logloss: 0.191477\ttraining's amex: 0.831533\tvalid_1's binary_logloss: 0.219847\tvalid_1's amex: 0.7889\n",
      "[900]\ttraining's binary_logloss: 0.188012\ttraining's amex: 0.837242\tvalid_1's binary_logloss: 0.219682\tvalid_1's amex: 0.788203\n",
      "[1000]\ttraining's binary_logloss: 0.184712\ttraining's amex: 0.842611\tvalid_1's binary_logloss: 0.219592\tvalid_1's amex: 0.788088\n",
      "[1100]\ttraining's binary_logloss: 0.181714\ttraining's amex: 0.847207\tvalid_1's binary_logloss: 0.219594\tvalid_1's amex: 0.787966\n",
      "[1200]\ttraining's binary_logloss: 0.178769\ttraining's amex: 0.852444\tvalid_1's binary_logloss: 0.21956\tvalid_1's amex: 0.787937\n",
      "[1300]\ttraining's binary_logloss: 0.175888\ttraining's amex: 0.857572\tvalid_1's binary_logloss: 0.2195\tvalid_1's amex: 0.788029\n",
      "\u001b[32m\u001b[1mFold 1 | 12:56 |  1332 trees |                Score = 0.78812\u001b[0m\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[100]\ttraining's binary_logloss: 0.252659\ttraining's amex: 0.768756\tvalid_1's binary_logloss: 0.255149\tvalid_1's amex: 0.764104\n",
      "[200]\ttraining's binary_logloss: 0.224242\ttraining's amex: 0.786567\tvalid_1's binary_logloss: 0.229549\tvalid_1's amex: 0.775263\n",
      "[300]\ttraining's binary_logloss: 0.214329\ttraining's amex: 0.799303\tvalid_1's binary_logloss: 0.223282\tvalid_1's amex: 0.781514\n",
      "[400]\ttraining's binary_logloss: 0.208088\ttraining's amex: 0.808725\tvalid_1's binary_logloss: 0.220727\tvalid_1's amex: 0.784211\n",
      "[500]\ttraining's binary_logloss: 0.203258\ttraining's amex: 0.815956\tvalid_1's binary_logloss: 0.219556\tvalid_1's amex: 0.786327\n",
      "[600]\ttraining's binary_logloss: 0.199055\ttraining's amex: 0.82176\tvalid_1's binary_logloss: 0.218884\tvalid_1's amex: 0.787717\n",
      "[700]\ttraining's binary_logloss: 0.195268\ttraining's amex: 0.827284\tvalid_1's binary_logloss: 0.218453\tvalid_1's amex: 0.788939\n",
      "[800]\ttraining's binary_logloss: 0.191789\ttraining's amex: 0.832727\tvalid_1's binary_logloss: 0.218227\tvalid_1's amex: 0.789432\n",
      "[900]\ttraining's binary_logloss: 0.188306\ttraining's amex: 0.838476\tvalid_1's binary_logloss: 0.218023\tvalid_1's amex: 0.789542\n",
      "[1000]\ttraining's binary_logloss: 0.185111\ttraining's amex: 0.84366\tvalid_1's binary_logloss: 0.217896\tvalid_1's amex: 0.789942\n",
      "[1100]\ttraining's binary_logloss: 0.182079\ttraining's amex: 0.848827\tvalid_1's binary_logloss: 0.217812\tvalid_1's amex: 0.790457\n",
      "[1200]\ttraining's binary_logloss: 0.179248\ttraining's amex: 0.853384\tvalid_1's binary_logloss: 0.217731\tvalid_1's amex: 0.790568\n",
      "[1300]\ttraining's binary_logloss: 0.17643\ttraining's amex: 0.857815\tvalid_1's binary_logloss: 0.217702\tvalid_1's amex: 0.790328\n",
      "\u001b[32m\u001b[1mFold 2 | 12:51 |  1332 trees |                Score = 0.79022\u001b[0m\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[100]\ttraining's binary_logloss: 0.253034\ttraining's amex: 0.767949\tvalid_1's binary_logloss: 0.254316\tvalid_1's amex: 0.763672\n",
      "[200]\ttraining's binary_logloss: 0.224536\ttraining's amex: 0.78581\tvalid_1's binary_logloss: 0.228422\tvalid_1's amex: 0.777632\n",
      "[300]\ttraining's binary_logloss: 0.214509\ttraining's amex: 0.798125\tvalid_1's binary_logloss: 0.222231\tvalid_1's amex: 0.784681\n",
      "[400]\ttraining's binary_logloss: 0.208382\ttraining's amex: 0.806773\tvalid_1's binary_logloss: 0.219665\tvalid_1's amex: 0.787851\n",
      "[500]\ttraining's binary_logloss: 0.203601\ttraining's amex: 0.814108\tvalid_1's binary_logloss: 0.218334\tvalid_1's amex: 0.790753\n",
      "[600]\ttraining's binary_logloss: 0.199545\ttraining's amex: 0.820311\tvalid_1's binary_logloss: 0.217631\tvalid_1's amex: 0.79086\n",
      "[700]\ttraining's binary_logloss: 0.195829\ttraining's amex: 0.825838\tvalid_1's binary_logloss: 0.217148\tvalid_1's amex: 0.791799\n",
      "[800]\ttraining's binary_logloss: 0.192269\ttraining's amex: 0.831341\tvalid_1's binary_logloss: 0.216857\tvalid_1's amex: 0.792655\n",
      "[900]\ttraining's binary_logloss: 0.189051\ttraining's amex: 0.836936\tvalid_1's binary_logloss: 0.216699\tvalid_1's amex: 0.792436\n",
      "[1000]\ttraining's binary_logloss: 0.185736\ttraining's amex: 0.842594\tvalid_1's binary_logloss: 0.216629\tvalid_1's amex: 0.792582\n",
      "[1100]\ttraining's binary_logloss: 0.182574\ttraining's amex: 0.847432\tvalid_1's binary_logloss: 0.216559\tvalid_1's amex: 0.792098\n",
      "[1200]\ttraining's binary_logloss: 0.179661\ttraining's amex: 0.851822\tvalid_1's binary_logloss: 0.216557\tvalid_1's amex: 0.791968\n",
      "[1300]\ttraining's binary_logloss: 0.176925\ttraining's amex: 0.856475\tvalid_1's binary_logloss: 0.216559\tvalid_1's amex: 0.792574\n",
      "\u001b[32m\u001b[1mFold 3 | 12:53 |  1332 trees |                Score = 0.79272\u001b[0m\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[100]\ttraining's binary_logloss: 0.252902\ttraining's amex: 0.767732\tvalid_1's binary_logloss: 0.25424\tvalid_1's amex: 0.764163\n",
      "[200]\ttraining's binary_logloss: 0.224541\ttraining's amex: 0.785135\tvalid_1's binary_logloss: 0.228599\tvalid_1's amex: 0.777983\n",
      "[300]\ttraining's binary_logloss: 0.214661\ttraining's amex: 0.797907\tvalid_1's binary_logloss: 0.222235\tvalid_1's amex: 0.785708\n",
      "[400]\ttraining's binary_logloss: 0.208421\ttraining's amex: 0.805317\tvalid_1's binary_logloss: 0.21964\tvalid_1's amex: 0.789131\n",
      "[500]\ttraining's binary_logloss: 0.203653\ttraining's amex: 0.813177\tvalid_1's binary_logloss: 0.218446\tvalid_1's amex: 0.79071\n",
      "[600]\ttraining's binary_logloss: 0.1995\ttraining's amex: 0.819489\tvalid_1's binary_logloss: 0.217797\tvalid_1's amex: 0.790678\n",
      "[700]\ttraining's binary_logloss: 0.19578\ttraining's amex: 0.825318\tvalid_1's binary_logloss: 0.217363\tvalid_1's amex: 0.791207\n",
      "[800]\ttraining's binary_logloss: 0.192177\ttraining's amex: 0.830814\tvalid_1's binary_logloss: 0.217086\tvalid_1's amex: 0.791349\n",
      "[900]\ttraining's binary_logloss: 0.188789\ttraining's amex: 0.83631\tvalid_1's binary_logloss: 0.216957\tvalid_1's amex: 0.791834\n",
      "[1000]\ttraining's binary_logloss: 0.185529\ttraining's amex: 0.841459\tvalid_1's binary_logloss: 0.2169\tvalid_1's amex: 0.792188\n",
      "[1100]\ttraining's binary_logloss: 0.182594\ttraining's amex: 0.846542\tvalid_1's binary_logloss: 0.216865\tvalid_1's amex: 0.791947\n",
      "[1200]\ttraining's binary_logloss: 0.179544\ttraining's amex: 0.851623\tvalid_1's binary_logloss: 0.216847\tvalid_1's amex: 0.792794\n",
      "[1300]\ttraining's binary_logloss: 0.176572\ttraining's amex: 0.856649\tvalid_1's binary_logloss: 0.216804\tvalid_1's amex: 0.792871\n",
      "\u001b[32m\u001b[1mFold 4 | 12:51 |  1332 trees |                Score = 0.79231\u001b[0m\n",
      "\u001b[32m\u001b[1mOOF Score:                       0.79106\u001b[0m\n",
      "CPU times: user 11h 36min 5s, sys: 13min 53s, total: 11h 49min 58s\n",
      "Wall time: 1h 5min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ONLY_FIRST_FOLD = False\n",
    "\n",
    "features = [f for f in train.columns if f != 'customer_ID' and f != 'target']\n",
    "\n",
    "def my_booster():\n",
    "    params = {\n",
    "            'learning_rate': 0.02410649590217162, \n",
    "            'n_estimators': 1332, \n",
    "            'max_depth': 16, \n",
    "            'min_child_samples': 3551, \n",
    "            'max_bin': 582, \n",
    "            'num_leaves': 929, \n",
    "            'random_state':42,\n",
    "            'feature_fraction':0.3,\n",
    "            'bagging_fraction':0.3\n",
    "            }\n",
    "    \n",
    "    return LGBMClassifier(**params)\n",
    "\n",
    "print(f'{len(features)} features**')\n",
    "\n",
    "score_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(train, target)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    X_tr = train.iloc[idx_tr][features]\n",
    "    X_va = train.iloc[idx_va][features]\n",
    "    y_tr = target.iloc[idx_tr]\n",
    "    y_va = target.iloc[idx_va]\n",
    "\n",
    "    model = my_booster()\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        model.fit(X_tr, y_tr,\n",
    "                eval_set=[(X_tr, y_tr), (X_va, y_va)],\n",
    "                eval_metric=[lgb_amex_metric],\n",
    "                callbacks=[log_evaluation(100)]) ##\n",
    "    y_va_pred = model.predict_proba(X_va)[:, 1]\n",
    "    score = amex_metric(y_va.values, y_va_pred)\n",
    "    n_trees = model.best_iteration_\n",
    "\n",
    "    if n_trees is None:\n",
    "        n_trees = model.n_estimators\n",
    "        \n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | {str(datetime.datetime.now() - start_time)[-12:-7]} |\"\n",
    "          f\" {n_trees:5} trees |\"\n",
    "          f\"                Score = {score:.5f}{Style.RESET_ALL}\")\n",
    "    score_list.append(score)\n",
    "    \n",
    "    if INFERENCE:\n",
    "        y_pred_list.append(model.predict_proba(test[features])[:,1])\n",
    "        \n",
    "    if ONLY_FIRST_FOLD: break # we only want the first fold\n",
    "    \n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}OOF Score:                       {np.mean(score_list):.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "  param = {\n",
    "      \"random_state\":42,\n",
    "      'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.05),\n",
    "      \"n_estimators\":trial.suggest_int(\"n_estimators\", 500, 2500),\n",
    "      \"max_depth\":trial.suggest_int(\"max_depth\", 6, 16),\n",
    "      \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 2000, 4000),\n",
    "      \"max_bin\": trial.suggest_int(\"max_bin\", 300, 600),\n",
    "      'num_leaves': trial.suggest_int(\"num_leaves\", 127, 1023),\n",
    "      'boosting_type': trial.suggest_categorical('boosting_type', ['dart', 'gbdt']),\n",
    "  }\n",
    "\n",
    "\n",
    "  lgbm = LGBMClassifier(**param)\n",
    "  lgbm.fit(X_tr, y_tr,\n",
    "                eval_set=[(X_tr, y_tr), (X_va, y_va)],\n",
    "                eval_metric=[lgb_amex_metric],\n",
    "                callbacks=[log_evaluation(100)])\n",
    "  preds = lgbm.predict(X_va)\n",
    "  score = amex_metric(y_va, preds)\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name = 'lgbm_parameter_opt',\n",
    "    direction = 'minimize',\n",
    "    sampler = sampler,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(\"Best Score:\",study.best_value)\n",
    "print(\"Best trial\",study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INFERENCE:\n",
    "    sub = pd.DataFrame({'customer_ID': test.index,\n",
    "                        'prediction': np.mean(y_pred_list, axis=0)})\n",
    "    sub.to_csv('results/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3b1f614b1596e3dfeedccb6ee4bbb4b3c66c39d76de8dd8646131c8c60a95b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kaggle-amex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
